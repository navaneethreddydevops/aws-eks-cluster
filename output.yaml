NAME: loki
LAST DEPLOYED: Sun Oct  6 04:11:12 2024
NAMESPACE: default
STATUS: pending-install
REVISION: 1
USER-SUPPLIED VALUES:
backend:
  replicas: 3
bloomCompactor:
  replicas: 0
bloomGateway:
  replicas: 0
compactor:
  replicas: 0
deploymentMode: SimpleScalable
distributor:
  replicas: 0
indexGateway:
  replicas: 0
ingester:
  replicas: 0
loki:
  ingester:
    chunk_encoding: snappy
  querier:
    max_concurrent: 4
  schemaConfig:
    configs:
    - from: "2024-04-01"
      index:
        period: 24h
        prefix: loki_index_
      object_store: s3
      schema: v13
      store: tsdb
  tracing:
    enabled: true
minio:
  enabled: true
querier:
  replicas: 0
queryFrontend:
  replicas: 0
queryScheduler:
  replicas: 0
read:
  replicas: 3
singleBinary:
  replicas: 0
write:
  replicas: 3

COMPUTED VALUES:
adminApi:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  initContainers: []
  labels: {}
  nodeSelector: {}
  podSecurityContext:
    runAsGroup: 10001
    runAsNonRoot: true
    runAsUser: 10001
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  replicas: 1
  resources: {}
  service:
    annotations: {}
    labels: {}
  strategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 60
  tolerations: []
backend:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: backend
        topologyKey: kubernetes.io/hostname
  annotations: {}
  autoscaling:
    behavior: {}
    enabled: false
    maxReplicas: 6
    minReplicas: 3
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
  dnsConfig: {}
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image:
    registry: null
    repository: null
    tag: null
  initContainers: []
  nodeSelector: {}
  persistence:
    annotations: {}
    dataVolumeParameters:
      emptyDir: {}
    enableStatefulSetAutoDeletePVC: true
    selector: null
    size: 10Gi
    storageClass: null
    volumeClaimsEnabled: true
  podAnnotations: {}
  podLabels: {}
  podManagementPolicy: Parallel
  priorityClassName: null
  replicas: 3
  resources: {}
  selectorLabels: {}
  service:
    annotations: {}
    labels: {}
  targetModule: backend
  terminationGracePeriodSeconds: 300
  tolerations: []
  topologySpreadConstraints: []
bloomBuilder:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: bloom-builder
        topologyKey: kubernetes.io/hostname
  appProtocol:
    grpc: ""
  autoscaling:
    behavior:
      enabled: false
      scaleDown: {}
      scaleUp: {}
    customMetrics: []
    enabled: false
    maxReplicas: 3
    minReplicas: 1
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
  command: null
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  maxUnavailable: null
  nodeSelector: {}
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  replicas: 0
  resources: {}
  serviceAnnotations: {}
  serviceLabels: {}
  terminationGracePeriodSeconds: 30
  tolerations: []
bloomCompactor:
  replicas: 0
bloomGateway:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: bloom-gateway
        topologyKey: kubernetes.io/hostname
  appProtocol:
    grpc: ""
  command: null
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  initContainers: []
  livenessProbe: {}
  nodeSelector: {}
  persistence:
    annotations: {}
    claims:
    - name: data
      size: 10Gi
      storageClass: null
    enableStatefulSetAutoDeletePVC: false
    enabled: false
    whenDeleted: Retain
    whenScaled: Retain
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  readinessProbe: {}
  replicas: 0
  resources: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: false
    imagePullSecrets: []
    name: null
  serviceAnnotations: {}
  serviceLabels: {}
  terminationGracePeriodSeconds: 30
  tolerations: []
bloomPlanner:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: bloom-planner
        topologyKey: kubernetes.io/hostname
  appProtocol:
    grpc: ""
  command: null
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  initContainers: []
  livenessProbe: {}
  nodeSelector: {}
  persistence:
    annotations: {}
    claims:
    - name: data
      size: 10Gi
      storageClass: null
    enableStatefulSetAutoDeletePVC: false
    enabled: false
    whenDeleted: Retain
    whenScaled: Retain
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  readinessProbe: {}
  replicas: 0
  resources: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: false
    imagePullSecrets: []
    name: null
  serviceAnnotations: {}
  serviceLabels: {}
  terminationGracePeriodSeconds: 30
  tolerations: []
chunksCache:
  affinity: {}
  allocatedMemory: 8192
  annotations: {}
  batchSize: 4
  connectionLimit: 16384
  defaultValidity: 0s
  enabled: true
  extraArgs: {}
  extraContainers: []
  extraExtendedOptions: ""
  extraVolumeMounts: []
  extraVolumes: []
  initContainers: []
  maxItemMemory: 5
  nodeSelector: {}
  parallelism: 5
  persistence:
    enabled: false
    mountPath: /data
    storageClass: null
    storageSize: 10G
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podManagementPolicy: Parallel
  port: 11211
  priorityClassName: null
  replicas: 1
  resources: null
  service:
    annotations: {}
    labels: {}
  statefulStrategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 60
  timeout: 2000ms
  tolerations: []
  topologySpreadConstraints: []
  writebackBuffer: 500000
  writebackParallelism: 1
  writebackSizeLimit: 500MB
clusterLabelOverride: null
compactor:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: compactor
        topologyKey: kubernetes.io/hostname
  appProtocol:
    grpc: ""
  command: null
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  initContainers: []
  livenessProbe: {}
  nodeSelector: {}
  persistence:
    annotations: {}
    claims:
    - name: data
      size: 10Gi
      storageClass: null
    enableStatefulSetAutoDeletePVC: false
    enabled: false
    size: 10Gi
    storageClass: null
    whenDeleted: Retain
    whenScaled: Retain
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  readinessProbe: {}
  replicas: 0
  resources: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: false
    imagePullSecrets: []
    name: null
  serviceAnnotations: {}
  serviceLabels: {}
  terminationGracePeriodSeconds: 30
  tolerations: []
deploymentMode: SimpleScalable
distributor:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: distributor
        topologyKey: kubernetes.io/hostname
  appProtocol:
    grpc: ""
  autoscaling:
    behavior:
      enabled: false
      scaleDown: {}
      scaleUp: {}
    customMetrics: []
    enabled: false
    maxReplicas: 3
    minReplicas: 1
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
  command: null
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  maxSurge: 0
  maxUnavailable: null
  nodeSelector: {}
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  replicas: 0
  resources: {}
  serviceAnnotations: {}
  serviceLabels: {}
  terminationGracePeriodSeconds: 30
  tolerations: []
enterprise:
  adminApi:
    enabled: true
  adminToken:
    additionalNamespaces: []
    secret: null
  canarySecret: null
  cluster_name: null
  config: |
    {{- if .Values.enterprise.adminApi.enabled }}
    admin_client:
      {{ include "enterprise-logs.adminAPIStorageConfig" . | nindent 2 }}
    {{ end }}
    auth:
      type: {{ .Values.enterprise.adminApi.enabled | ternary "enterprise" "trust" }}
    auth_enabled: {{ .Values.loki.auth_enabled }}
    cluster_name: {{ include "loki.clusterName" . }}
    license:
      path: /etc/loki/license/license.jwt
  enabled: false
  externalConfigName: ""
  externalLicenseName: null
  gelGateway: true
  image:
    digest: null
    pullPolicy: IfNotPresent
    registry: docker.io
    repository: grafana/enterprise-logs
    tag: null
  license:
    contents: NOTAVALIDLICENSE
  provisioner:
    additionalTenants: []
    affinity: {}
    annotations: {}
    enabled: true
    env: []
    extraVolumeMounts: []
    image:
      digest: null
      pullPolicy: IfNotPresent
      registry: docker.io
      repository: grafana/enterprise-logs-provisioner
      tag: null
    labels: {}
    nodeSelector: {}
    priorityClassName: null
    provisionedSecretPrefix: null
    securityContext:
      fsGroup: 10001
      runAsGroup: 10001
      runAsNonRoot: true
      runAsUser: 10001
    tolerations: []
  tokengen:
    affinity: {}
    annotations: {}
    enabled: true
    env: []
    extraArgs: []
    extraEnvFrom: []
    extraVolumeMounts: []
    extraVolumes: []
    labels: {}
    nodeSelector: {}
    priorityClassName: ""
    securityContext:
      fsGroup: 10001
      runAsGroup: 10001
      runAsNonRoot: true
      runAsUser: 10001
    targetModule: tokengen
    tolerations: []
  useExternalLicense: false
  version: 3.1.1
enterpriseGateway:
  affinity: {}
  annotations: {}
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  env: []
  extraArgs: {}
  extraContainers: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  initContainers: []
  labels: {}
  nodeSelector: {}
  podSecurityContext:
    fsGroup: 10001
    runAsGroup: 10001
    runAsNonRoot: true
    runAsUser: 10001
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  replicas: 1
  resources: {}
  service:
    annotations: {}
    labels: {}
    type: ClusterIP
  strategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 60
  tolerations: []
  useDefaultProxyURLs: true
extraObjects: []
fullnameOverride: null
gateway:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: gateway
        topologyKey: kubernetes.io/hostname
  annotations: {}
  autoscaling:
    behavior: {}
    enabled: false
    maxReplicas: 3
    minReplicas: 1
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
  basicAuth:
    enabled: false
    existingSecret: null
    htpasswd: |-
      {{ if .Values.loki.tenants }}


        {{- range $t := .Values.loki.tenants }}
      {{ htpasswd (required "All tenants must have a 'name' set" $t.name) (required "All tenants must have a 'password' set" $t.password) }}


        {{- end }}
      {{ else }} {{ htpasswd (required "'gateway.basicAuth.username' is required" .Values.gateway.basicAuth.username) (required "'gateway.basicAuth.password' is required" .Values.gateway.basicAuth.password) }} {{ end }}
    password: null
    username: null
  containerPort: 8080
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  deploymentStrategy:
    type: RollingUpdate
  dnsConfig: {}
  enabled: true
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image:
    digest: null
    pullPolicy: IfNotPresent
    registry: docker.io
    repository: nginxinc/nginx-unprivileged
    tag: 1.27-alpine
  ingress:
    annotations: {}
    enabled: false
    hosts:
    - host: gateway.loki.example.com
      paths:
      - path: /
    ingressClassName: ""
    labels: {}
    tls:
    - hosts:
      - gateway.loki.example.com
      secretName: loki-gateway-tls
  lifecycle: {}
  nginxConfig:
    customBackendUrl: null
    customReadUrl: null
    customWriteUrl: null
    enableIPv6: true
    file: |
      {{- include "loki.nginxFile" . | indent 2 -}}
    httpSnippet: '{{ if .Values.loki.tenants }}proxy_set_header X-Scope-OrgID $remote_user;{{
      end }}'
    logFormat: |-
      main '$remote_addr - $remote_user [$time_local]  $status '
              '"$request" $body_bytes_sent "$http_referer" '
              '"$http_user_agent" "$http_x_forwarded_for"';
    resolver: ""
    schema: http
    serverSnippet: ""
    ssl: false
  nodeSelector: {}
  podAnnotations: {}
  podLabels: {}
  podSecurityContext:
    fsGroup: 101
    runAsGroup: 101
    runAsNonRoot: true
    runAsUser: 101
  priorityClassName: null
  readinessProbe:
    httpGet:
      path: /
      port: http-metrics
    initialDelaySeconds: 15
    timeoutSeconds: 1
  replicas: 1
  resources: {}
  service:
    annotations: {}
    clusterIP: null
    labels: {}
    loadBalancerIP: null
    nodePort: null
    port: 80
    type: ClusterIP
  terminationGracePeriodSeconds: 30
  tolerations: []
  topologySpreadConstraints: []
  verboseLogging: true
global:
  clusterDomain: cluster.local
  dnsNamespace: kube-system
  dnsService: kube-dns
  image:
    registry: null
  priorityClassName: null
imagePullSecrets: []
indexGateway:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: index-gateway
        topologyKey: kubernetes.io/hostname
  appProtocol:
    grpc: ""
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  initContainers: []
  joinMemberlist: true
  maxUnavailable: null
  nodeSelector: {}
  persistence:
    annotations: {}
    enableStatefulSetAutoDeletePVC: false
    enabled: false
    inMemory: false
    size: 10Gi
    storageClass: null
    whenDeleted: Retain
    whenScaled: Retain
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  replicas: 0
  resources: {}
  serviceAnnotations: {}
  serviceLabels: {}
  terminationGracePeriodSeconds: 300
  tolerations: []
ingester:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: ingester
        topologyKey: kubernetes.io/hostname
  appProtocol:
    grpc: ""
  autoscaling:
    behavior:
      enabled: false
      scaleDown: {}
      scaleUp: {}
    customMetrics: []
    enabled: false
    maxReplicas: 3
    minReplicas: 1
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
  command: null
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  initContainers: []
  lifecycle: {}
  livenessProbe: {}
  maxUnavailable: 1
  nodeSelector: {}
  persistence:
    claims:
    - name: data
      size: 10Gi
      storageClass: null
    enableStatefulSetAutoDeletePVC: false
    enabled: false
    inMemory: false
    whenDeleted: Retain
    whenScaled: Retain
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  readinessProbe: {}
  replicas: 0
  resources: {}
  serviceAnnotations: {}
  serviceLabels: {}
  terminationGracePeriodSeconds: 300
  tolerations: []
  topologySpreadConstraints:
  - labelSelector:
      matchLabels:
        app.kubernetes.io/component: ingester
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
  zoneAwareReplication:
    enabled: true
    maxUnavailablePct: 33
    migration:
      enabled: false
      excludeDefaultZone: false
      readPath: false
      writePath: false
    zoneA:
      annotations: {}
      extraAffinity: {}
      nodeSelector: null
      podAnnotations: {}
    zoneB:
      annotations: {}
      extraAffinity: {}
      nodeSelector: null
      podAnnotations: {}
    zoneC:
      annotations: {}
      extraAffinity: {}
      nodeSelector: null
      podAnnotations: {}
ingress:
  annotations: {}
  enabled: false
  hosts:
  - loki.example.com
  ingressClassName: ""
  labels: {}
  paths:
    distributor:
    - /api/prom/push
    - /loki/api/v1/push
    - /otlp/v1/logs
    queryFrontend:
    - /api/prom/query
    - /api/prom/label
    - /api/prom/series
    - /api/prom/tail
    - /loki/api/v1/query
    - /loki/api/v1/query_range
    - /loki/api/v1/tail
    - /loki/api/v1/label
    - /loki/api/v1/labels
    - /loki/api/v1/series
    - /loki/api/v1/index/stats
    - /loki/api/v1/index/volume
    - /loki/api/v1/index/volume_range
    - /loki/api/v1/format_query
    - /loki/api/v1/detected_fields
    - /loki/api/v1/detected_labels
    - /loki/api/v1/patterns
    ruler:
    - /api/prom/rules
    - /api/prom/api/v1/rules
    - /api/prom/api/v1/alerts
    - /loki/api/v1/rules
    - /prometheus/api/v1/rules
    - /prometheus/api/v1/alerts
  tls: []
kubectlImage:
  digest: null
  pullPolicy: IfNotPresent
  registry: docker.io
  repository: bitnami/kubectl
  tag: null
loki:
  analytics: {}
  annotations: {}
  auth_enabled: true
  bloom_build:
    builder:
      planner_address: '{{ include "loki.bloomPlannerAddress" . }}'
    enabled: false
  bloom_gateway:
    client:
      addresses: '{{ include "loki.bloomGatewayAddresses" . }}'
    enabled: false
  commonConfig:
    compactor_address: '{{ include "loki.compactorAddress" . }}'
    path_prefix: /var/loki
    replication_factor: 3
  compactor: {}
  config: |
    {{- if .Values.enterprise.enabled}}
    {{- tpl .Values.enterprise.config . }}
    {{- else }}
    auth_enabled: {{ .Values.loki.auth_enabled }}
    {{- end }}

    {{- with .Values.loki.server }}
    server:
      {{- toYaml . | nindent 2}}
    {{- end}}

    pattern_ingester:
      enabled: {{ .Values.loki.pattern_ingester.enabled }}

    memberlist:
    {{- if .Values.loki.memberlistConfig }}
      {{- toYaml .Values.loki.memberlistConfig | nindent 2 }}
    {{- else }}
    {{- if .Values.loki.extraMemberlistConfig}}
    {{- toYaml .Values.loki.extraMemberlistConfig | nindent 2}}
    {{- end }}
      join_members:
        - {{ include "loki.memberlist" . }}
        {{- with .Values.migrate.fromDistributed }}
        {{- if .enabled }}
        - {{ .memberlistService }}
        {{- end }}
        {{- end }}
    {{- end }}

    {{- with .Values.loki.ingester }}
    ingester:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}

    {{- if .Values.loki.commonConfig}}
    common:
    {{- toYaml .Values.loki.commonConfig | nindent 2}}
      storage:
      {{- include "loki.commonStorageConfig" . | nindent 4}}
    {{- end}}

    {{- with .Values.loki.limits_config }}
    limits_config:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}

    runtime_config:
      file: /etc/loki/runtime-config/runtime-config.yaml

    {{- with .Values.chunksCache }}
    {{- if .enabled }}
    chunk_store_config:
      chunk_cache_config:
        default_validity: {{ .defaultValidity }}
        background:
          writeback_goroutines: {{ .writebackParallelism }}
          writeback_buffer: {{ .writebackBuffer }}
          writeback_size_limit: {{ .writebackSizeLimit }}
        memcached:
          batch_size: {{ .batchSize }}
          parallelism: {{ .parallelism }}
        memcached_client:
          addresses: dnssrvnoa+_memcached-client._tcp.{{ template "loki.fullname" $ }}-chunks-cache.{{ $.Release.Namespace }}.svc
          consistent_hash: true
          timeout: {{ .timeout }}
          max_idle_conns: 72
    {{- end }}
    {{- end }}

    {{- if .Values.loki.schemaConfig }}
    schema_config:
    {{- toYaml .Values.loki.schemaConfig | nindent 2}}
    {{- end }}

    {{- if .Values.loki.useTestSchema }}
    schema_config:
    {{- toYaml .Values.loki.testSchemaConfig | nindent 2}}
    {{- end }}

    {{ include "loki.rulerConfig" . }}

    {{- if or .Values.tableManager.retention_deletes_enabled .Values.tableManager.retention_period }}
    table_manager:
      retention_deletes_enabled: {{ .Values.tableManager.retention_deletes_enabled }}
      retention_period: {{ .Values.tableManager.retention_period }}
    {{- end }}

    query_range:
      align_queries_with_step: true
      {{- with .Values.loki.query_range }}
      {{- tpl (. | toYaml) $ | nindent 2 }}
      {{- end }}
      {{- if .Values.resultsCache.enabled }}
      {{- with .Values.resultsCache }}
      cache_results: true
      results_cache:
        cache:
          default_validity: {{ .defaultValidity }}
          background:
            writeback_goroutines: {{ .writebackParallelism }}
            writeback_buffer: {{ .writebackBuffer }}
            writeback_size_limit: {{ .writebackSizeLimit }}
          memcached_client:
            consistent_hash: true
            addresses: dnssrvnoa+_memcached-client._tcp.{{ template "loki.fullname" $ }}-results-cache.{{ $.Release.Namespace }}.svc
            timeout: {{ .timeout }}
            update_interval: 1m
      {{- end }}
      {{- end }}

    {{- with .Values.loki.storage_config }}
    storage_config:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}

    {{- with .Values.loki.query_scheduler }}
    query_scheduler:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}

    {{- with .Values.loki.compactor }}
    compactor:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}

    {{- with .Values.loki.analytics }}
    analytics:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}

    {{- with .Values.loki.querier }}
    querier:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}

    {{- with .Values.loki.index_gateway }}
    index_gateway:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}

    {{- with .Values.loki.frontend }}
    frontend:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}

    {{- with .Values.loki.frontend_worker }}
    frontend_worker:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}

    {{- with .Values.loki.distributor }}
    distributor:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}

    tracing:
      enabled: {{ .Values.loki.tracing.enabled }}

    {{- with .Values.loki.bloom_build }}
    bloom_build:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}

    {{- with .Values.loki.bloom_gateway }}
    bloom_gateway:
      {{- tpl (. | toYaml) $ | nindent 4 }}
    {{- end }}
  configObjectName: '{{ include "loki.name" . }}'
  configStorageType: ConfigMap
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  distributor: {}
  enableServiceLinks: true
  extraMemberlistConfig: {}
  frontend:
    scheduler_address: '{{ include "loki.querySchedulerAddress" . }}'
    tail_proxy_url: '{{ include "loki.querierAddress" . }}'
  frontend_worker:
    scheduler_address: '{{ include "loki.querySchedulerAddress" . }}'
  generatedConfigObjectName: '{{ include "loki.name" . }}'
  image:
    digest: null
    pullPolicy: IfNotPresent
    registry: docker.io
    repository: grafana/loki
    tag: null
  index_gateway:
    mode: simple
  ingester:
    chunk_encoding: snappy
  limits_config:
    max_cache_freshness_per_query: 10m
    query_timeout: 300s
    reject_old_samples: true
    reject_old_samples_max_age: 168h
    split_queries_by_interval: 15m
    volume_enabled: true
  memberlistConfig: {}
  memcached:
    chunk_cache:
      batch_size: 256
      enabled: false
      host: ""
      parallelism: 10
      service: memcached-client
    results_cache:
      default_validity: 12h
      enabled: false
      host: ""
      service: memcached-client
      timeout: 500ms
  pattern_ingester:
    enabled: false
  podAnnotations: {}
  podLabels: {}
  podSecurityContext:
    fsGroup: 10001
    runAsGroup: 10001
    runAsNonRoot: true
    runAsUser: 10001
  querier:
    max_concurrent: 4
  query_range: {}
  query_scheduler: {}
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 30
    timeoutSeconds: 1
  revisionHistoryLimit: 10
  rulerConfig: {}
  runtimeConfig: {}
  schemaConfig:
    configs:
    - from: "2024-04-01"
      index:
        period: 24h
        prefix: loki_index_
      object_store: s3
      schema: v13
      store: tsdb
  server:
    grpc_listen_port: 9095
    http_listen_port: 3100
    http_server_read_timeout: 600s
    http_server_write_timeout: 600s
  serviceAnnotations: {}
  serviceLabels: {}
  storage:
    azure:
      accountKey: null
      accountName: null
      connectionString: null
      endpointSuffix: null
      requestTimeout: null
      useFederatedToken: false
      useManagedIdentity: false
      userAssignedId: null
    filesystem:
      admin_api_directory: /var/loki/admin
      chunks_directory: /var/loki/chunks
      rules_directory: /var/loki/rules
    gcs:
      chunkBufferSize: 0
      enableHttp2: true
      requestTimeout: 0s
    s3:
      accessKeyId: null
      backoff_config: {}
      disable_dualstack: false
      endpoint: null
      http_config: {}
      insecure: false
      region: null
      s3: null
      s3ForcePathStyle: false
      secretAccessKey: null
      signatureVersion: null
    swift:
      auth_url: null
      auth_version: null
      connect_timeout: null
      container_name: null
      domain_id: null
      domain_name: null
      internal: null
      max_retries: null
      password: null
      project_domain_id: null
      project_domain_name: null
      project_id: null
      project_name: null
      region_name: null
      request_timeout: null
      user_domain_id: null
      user_domain_name: null
      user_id: null
      username: null
    type: s3
  storage_config:
    bloom_shipper:
      working_directory: /var/loki/data/bloomshipper
    boltdb_shipper:
      index_gateway_client:
        server_address: '{{ include "loki.indexGatewayAddress" . }}'
    hedging:
      at: 250ms
      max_per_second: 20
      up_to: 3
    tsdb_shipper:
      index_gateway_client:
        server_address: '{{ include "loki.indexGatewayAddress" . }}'
  structuredConfig: {}
  tenants: []
  testSchemaConfig:
    configs:
    - from: "2024-04-01"
      index:
        period: 24h
        prefix: index_
      object_store: '{{ include "loki.testSchemaObjectStore" . }}'
      schema: v13
      store: tsdb
  tracing:
    enabled: true
  useTestSchema: false
lokiCanary:
  annotations: {}
  dnsConfig: {}
  enabled: true
  extraArgs: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image:
    digest: null
    pullPolicy: IfNotPresent
    registry: docker.io
    repository: grafana/loki-canary
    tag: null
  labelname: pod
  nodeSelector: {}
  podLabels: {}
  priorityClassName: null
  push: true
  resources: {}
  service:
    annotations: {}
    labels: {}
  tolerations: []
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
memberlist:
  service:
    annotations: {}
    publishNotReadyAddresses: false
memcached:
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  image:
    pullPolicy: IfNotPresent
    repository: memcached
    tag: 1.6.23-alpine
  podSecurityContext:
    fsGroup: 11211
    runAsGroup: 11211
    runAsNonRoot: true
    runAsUser: 11211
  priorityClassName: null
memcachedExporter:
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
  enabled: true
  extraArgs: {}
  image:
    pullPolicy: IfNotPresent
    repository: prom/memcached-exporter
    tag: v0.14.2
  resources:
    limits: {}
    requests: {}
migrate:
  fromDistributed:
    enabled: false
    memberlistService: ""
minio:
  DeploymentUpdate:
    maxSurge: 100%
    maxUnavailable: 0
    type: RollingUpdate
  StatefulSetUpdate:
    updateStrategy: RollingUpdate
  additionalAnnotations: {}
  additionalLabels: {}
  address: null
  affinity: {}
  bucketRoot: ""
  buckets:
  - name: chunks
    policy: none
    purge: false
  - name: ruler
    policy: none
    purge: false
  - name: admin
    policy: none
    purge: false
  certsPath: /etc/minio/certs/
  clusterDomain: cluster.local
  configPathmc: /etc/minio/mc/
  consoleIngress:
    annotations: {}
    enabled: false
    hosts:
    - console.minio-example.local
    labels: {}
    path: /
    tls: []
  consoleService:
    nodePort: 32001
    port: "9001"
    type: ClusterIP
  customCommandJob:
    affinity: {}
    annotations: {}
    exitCommand: ""
    nodeSelector: {}
    podAnnotations: {}
    resources:
      requests:
        memory: 128Mi
    securityContext:
      enabled: false
      fsGroup: 1000
      runAsGroup: 1000
      runAsUser: 1000
    tolerations: []
  drivesPerNode: 2
  enabled: true
  etcd:
    clientCert: ""
    clientCertKey: ""
    corednsPathPrefix: ""
    endpoints: []
    pathPrefix: ""
  existingSecret: ""
  extraArgs: []
  extraVolumeMounts: []
  extraVolumes: []
  fullnameOverride: ""
  gateway:
    replicas: 4
    type: nas
  global:
    clusterDomain: cluster.local
    dnsNamespace: kube-system
    dnsService: kube-dns
    image:
      registry: null
    priorityClassName: null
  ignoreChartChecksums: false
  image:
    pullPolicy: IfNotPresent
    repository: quay.io/minio/minio
    tag: RELEASE.2022-09-17T00-09-45Z
  imagePullSecrets: []
  ingress:
    annotations: {}
    enabled: false
    hosts:
    - minio-example.local
    labels: {}
    path: /
    tls: []
  makeBucketJob:
    affinity: {}
    annotations: {}
    exitCommand: ""
    extraVolumeMounts: []
    extraVolumes: []
    nodeSelector: {}
    podAnnotations: {}
    resources:
      requests:
        memory: 128Mi
    securityContext:
      enabled: false
      fsGroup: 1000
      runAsGroup: 1000
      runAsUser: 1000
    tolerations: []
  makePolicyJob:
    affinity: {}
    annotations: {}
    exitCommand: ""
    extraVolumeMounts: []
    extraVolumes: []
    nodeSelector: {}
    podAnnotations: {}
    resources:
      requests:
        memory: 128Mi
    securityContext:
      enabled: false
      fsGroup: 1000
      runAsGroup: 1000
      runAsUser: 1000
    tolerations: []
  makeUserJob:
    affinity: {}
    annotations: {}
    exitCommand: ""
    extraVolumeMounts: []
    extraVolumes: []
    nodeSelector: {}
    podAnnotations: {}
    resources:
      requests:
        memory: 128Mi
    securityContext:
      enabled: false
      fsGroup: 1000
      runAsGroup: 1000
      runAsUser: 1000
    tolerations: []
  mcImage:
    pullPolicy: IfNotPresent
    repository: quay.io/minio/mc
    tag: RELEASE.2022-09-16T09-16-47Z
  metrics:
    serviceMonitor:
      additionalLabels: {}
      enabled: false
      includeNode: false
      public: true
      relabelConfigs: {}
      relabelConfigsCluster: {}
  minioAPIPort: "9000"
  minioConsolePort: "9001"
  mode: distributed
  mountPath: /export
  nameOverride: ""
  networkPolicy:
    allowExternal: true
    enabled: false
  nodeSelector: {}
  oidc:
    claimName: policy
    claimPrefix: ""
    clientId: minio
    clientSecret: ""
    comment: ""
    configUrl: https://identity-provider-url/.well-known/openid-configuration
    enabled: false
    redirectUri: https://console-endpoint-url/oauth_callback
    scopes: openid,profile,email
  persistence:
    VolumeName: ""
    accessMode: ReadWriteOnce
    annotations: {}
    enabled: true
    existingClaim: ""
    size: 5Gi
    storageClass: ""
    subPath: ""
  podAnnotations: {}
  podDisruptionBudget:
    enabled: false
    maxUnavailable: 1
  podLabels: {}
  policies: []
  pools: 1
  priorityClassName: ""
  replicas: 1
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  rootPassword: supersecret
  rootUser: enterprise-logs
  runtimeClassName: ""
  securityContext:
    enabled: true
    fsGroup: 1000
    fsGroupChangePolicy: OnRootMismatch
    runAsGroup: 1000
    runAsUser: 1000
  service:
    nodePort: 32000
    port: "9000"
    type: ClusterIP
  serviceAccount:
    create: true
    name: minio-sa
  tls:
    certSecret: ""
    enabled: false
    privateKey: private.key
    publicCrt: public.crt
  tolerations: []
  topologySpreadConstraints: []
  trustedCertsSecret: ""
  users:
  - accessKey: console
    policy: consoleAdmin
    secretKey: console123
monitoring:
  dashboards:
    annotations: {}
    enabled: false
    labels:
      grafana_dashboard: "1"
    namespace: null
  rules:
    additionalGroups: []
    additionalRuleLabels: {}
    alerting: true
    annotations: {}
    disabled: {}
    enabled: false
    labels: {}
    namespace: null
  selfMonitoring:
    enabled: false
    grafanaAgent:
      annotations: {}
      enableConfigReadAPI: false
      installOperator: false
      labels: {}
      priorityClassName: null
      resources: {}
      tolerations: []
    logsInstance:
      annotations: {}
      clients: null
      labels: {}
    podLogs:
      additionalPipelineStages: []
      annotations: {}
      apiVersion: monitoring.grafana.com/v1alpha1
      labels: {}
      relabelings: []
    tenant:
      name: self-monitoring
      password: null
      secretNamespace: '{{ .Release.Namespace }}'
  serviceMonitor:
    annotations: {}
    enabled: false
    interval: 15s
    labels: {}
    metricRelabelings: []
    metricsInstance:
      annotations: {}
      enabled: true
      labels: {}
      remoteWrite: null
    namespaceSelector: {}
    relabelings: []
    scheme: http
    scrapeTimeout: null
    tlsConfig: null
nameOverride: null
networkPolicy:
  alertmanager:
    namespaceSelector: {}
    podSelector: {}
    port: 9093
  discovery:
    namespaceSelector: {}
    podSelector: {}
    port: null
  egressKubeApiserver:
    enabled: false
  egressWorld:
    enabled: false
  enabled: false
  externalStorage:
    cidrs: []
    ports: []
  flavor: kubernetes
  ingress:
    namespaceSelector: {}
    podSelector: {}
  metrics:
    cidrs: []
    namespaceSelector: {}
    podSelector: {}
patternIngester:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: pattern-ingester
        topologyKey: kubernetes.io/hostname
  appProtocol:
    grpc: ""
  command: null
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  initContainers: []
  livenessProbe: {}
  nodeSelector: {}
  persistence:
    annotations: {}
    claims:
    - name: data
      size: 10Gi
      storageClass: null
    enableStatefulSetAutoDeletePVC: false
    enabled: false
    size: 10Gi
    storageClass: null
    whenDeleted: Retain
    whenScaled: Retain
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  readinessProbe: {}
  replicas: 0
  resources: {}
  serviceAccount:
    annotations: {}
    automountServiceAccountToken: true
    create: false
    imagePullSecrets: []
    name: null
  serviceAnnotations: {}
  serviceLabels: {}
  terminationGracePeriodSeconds: 30
  tolerations: []
querier:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: querier
        topologyKey: kubernetes.io/hostname
  appProtocol:
    grpc: ""
  autoscaling:
    behavior:
      enabled: false
      scaleDown: {}
      scaleUp: {}
    customMetrics: []
    enabled: false
    maxReplicas: 3
    minReplicas: 1
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
  command: null
  dnsConfig: {}
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  initContainers: []
  maxSurge: 0
  maxUnavailable: null
  nodeSelector: {}
  persistence:
    annotations: {}
    enabled: false
    size: 10Gi
    storageClass: null
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  replicas: 0
  resources: {}
  serviceAnnotations: {}
  serviceLabels: {}
  terminationGracePeriodSeconds: 30
  tolerations: []
  topologySpreadConstraints:
  - labelSelector:
      matchLabels:
        app.kubernetes.io/component: querier
    maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
queryFrontend:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: query-frontend
        topologyKey: kubernetes.io/hostname
  appProtocol:
    grpc: ""
  autoscaling:
    behavior:
      enabled: false
      scaleDown: {}
      scaleUp: {}
    customMetrics: []
    enabled: false
    maxReplicas: 3
    minReplicas: 1
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
  command: null
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  maxUnavailable: null
  nodeSelector: {}
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  replicas: 0
  resources: {}
  serviceAnnotations: {}
  serviceLabels: {}
  terminationGracePeriodSeconds: 30
  tolerations: []
queryScheduler:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: query-scheduler
        topologyKey: kubernetes.io/hostname
  appProtocol:
    grpc: ""
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  maxUnavailable: 1
  nodeSelector: {}
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  replicas: 0
  resources: {}
  serviceAnnotations: {}
  serviceLabels: {}
  terminationGracePeriodSeconds: 30
  tolerations: []
rbac:
  namespaced: false
  pspAnnotations: {}
  pspEnabled: false
  sccEnabled: false
read:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: read
        topologyKey: kubernetes.io/hostname
  annotations: {}
  autoscaling:
    behavior: {}
    enabled: false
    maxReplicas: 6
    minReplicas: 2
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
  dnsConfig: {}
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image:
    registry: null
    repository: null
    tag: null
  legacyReadTarget: false
  lifecycle: {}
  nodeSelector: {}
  persistence:
    annotations: {}
    enableStatefulSetAutoDeletePVC: true
    selector: null
    size: 10Gi
    storageClass: null
  podAnnotations: {}
  podLabels: {}
  podManagementPolicy: Parallel
  priorityClassName: null
  replicas: 3
  resources: {}
  selectorLabels: {}
  service:
    annotations: {}
    labels: {}
  targetModule: read
  terminationGracePeriodSeconds: 30
  tolerations: []
  topologySpreadConstraints: []
resultsCache:
  affinity: {}
  allocatedMemory: 1024
  annotations: {}
  connectionLimit: 16384
  defaultValidity: 12h
  enabled: true
  extraArgs: {}
  extraContainers: []
  extraExtendedOptions: ""
  extraVolumeMounts: []
  extraVolumes: []
  initContainers: []
  maxItemMemory: 5
  nodeSelector: {}
  persistence:
    enabled: false
    mountPath: /data
    storageClass: null
    storageSize: 10G
  podAnnotations: {}
  podDisruptionBudget:
    maxUnavailable: 1
  podLabels: {}
  podManagementPolicy: Parallel
  port: 11211
  priorityClassName: null
  replicas: 1
  resources: null
  service:
    annotations: {}
    labels: {}
  statefulStrategy:
    type: RollingUpdate
  terminationGracePeriodSeconds: 60
  timeout: 500ms
  tolerations: []
  topologySpreadConstraints: []
  writebackBuffer: 500000
  writebackParallelism: 1
  writebackSizeLimit: 500MB
rollout_operator:
  enabled: false
  podSecurityContext:
    fsGroup: 10001
    runAsGroup: 10001
    runAsNonRoot: true
    runAsUser: 10001
    seccompProfile:
      type: RuntimeDefault
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: true
ruler:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: ruler
        topologyKey: kubernetes.io/hostname
  appProtocol:
    grpc: ""
  command: null
  directories: {}
  dnsConfig: {}
  enabled: true
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  hostAliases: []
  image:
    registry: null
    repository: null
    tag: null
  initContainers: []
  maxUnavailable: null
  nodeSelector: {}
  persistence:
    annotations: {}
    enabled: false
    size: 10Gi
    storageClass: null
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  replicas: 0
  resources: {}
  serviceAnnotations: {}
  serviceLabels: {}
  terminationGracePeriodSeconds: 300
  tolerations: []
serviceAccount:
  annotations: {}
  automountServiceAccountToken: true
  create: true
  imagePullSecrets: []
  labels: {}
  name: null
sidecar:
  enableUniqueFilenames: false
  image:
    pullPolicy: IfNotPresent
    repository: kiwigrid/k8s-sidecar
    sha: ""
    tag: 1.27.5
  livenessProbe: {}
  readinessProbe: {}
  resources: {}
  rules:
    enabled: true
    folder: /rules
    label: loki_rule
    labelValue: ""
    logLevel: INFO
    resource: both
    script: null
    searchNamespace: null
    watchClientTimeout: 60
    watchMethod: WATCH
    watchServerTimeout: 60
  securityContext: {}
  skipTlsVerify: false
singleBinary:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: single-binary
        topologyKey: kubernetes.io/hostname
  annotations: {}
  autoscaling:
    enabled: false
    maxReplicas: 3
    minReplicas: 1
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
  dnsConfig: {}
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image:
    registry: null
    repository: null
    tag: null
  initContainers: []
  nodeSelector: {}
  persistence:
    annotations: {}
    enableStatefulSetAutoDeletePVC: true
    enabled: true
    selector: null
    size: 10Gi
    storageClass: null
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  replicas: 0
  resources: {}
  selectorLabels: {}
  service:
    annotations: {}
    labels: {}
  targetModule: all
  terminationGracePeriodSeconds: 30
  tolerations: []
tableManager:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: table-manager
        topologyKey: kubernetes.io/hostname
  annotations: {}
  command: null
  dnsConfig: {}
  enabled: false
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeMounts: []
  extraVolumes: []
  image:
    registry: null
    repository: null
    tag: null
  nodeSelector: {}
  podAnnotations: {}
  podLabels: {}
  priorityClassName: null
  resources: {}
  retention_deletes_enabled: false
  retention_period: 0
  service:
    annotations: {}
    labels: {}
  terminationGracePeriodSeconds: 30
  tolerations: []
test:
  annotations: {}
  canaryServiceAddress: http://loki-canary:3500/metrics
  enabled: true
  image:
    digest: null
    pullPolicy: IfNotPresent
    registry: docker.io
    repository: grafana/loki-helm-test
    tag: ewelch-distributed-helm-chart-17db5ee
  labels: {}
  prometheusAddress: ""
  timeout: 1m
write:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: write
        topologyKey: kubernetes.io/hostname
  annotations: {}
  autoscaling:
    behavior:
      scaleDown:
        policies:
        - periodSeconds: 1800
          type: Pods
          value: 1
        stabilizationWindowSeconds: 3600
      scaleUp:
        policies:
        - periodSeconds: 900
          type: Pods
          value: 1
    enabled: false
    maxReplicas: 6
    minReplicas: 2
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: null
  dnsConfig: {}
  extraArgs: []
  extraContainers: []
  extraEnv: []
  extraEnvFrom: []
  extraVolumeClaimTemplates: []
  extraVolumeMounts: []
  extraVolumes: []
  image:
    registry: null
    repository: null
    tag: null
  initContainers: []
  lifecycle: {}
  nodeSelector: {}
  persistence:
    annotations: {}
    dataVolumeParameters:
      emptyDir: {}
    enableStatefulSetAutoDeletePVC: false
    selector: null
    size: 10Gi
    storageClass: null
    volumeClaimsEnabled: true
  podAnnotations: {}
  podLabels: {}
  podManagementPolicy: Parallel
  priorityClassName: null
  replicas: 3
  resources: {}
  selectorLabels: {}
  service:
    annotations: {}
    labels: {}
  targetModule: write
  terminationGracePeriodSeconds: 300
  tolerations: []
  topologySpreadConstraints: []

HOOKS:
---
# Source: loki/templates/tests/test-canary.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "loki-helm-test"
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: helm-test
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: loki-helm-test
      image: docker.io/grafana/loki-helm-test:ewelch-distributed-helm-chart-17db5ee
      env:
        - name: CANARY_SERVICE_ADDRESS
          value: "http://loki-canary:3500/metrics"
        - name: CANARY_PROMETHEUS_ADDRESS
          value: ""
        - name: CANARY_TEST_TIMEOUT
          value: "1m"
      args:
        - -test.v
  restartPolicy: Never
---
# Source: loki/charts/minio/templates/post-install-create-bucket-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: loki-minio-make-bucket-job
  namespace: "default"
  labels:
    app: minio-make-bucket-job
    chart: minio-4.0.15
    release: loki
    heritage: Helm
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  template:
    metadata:
      labels:
        app: minio-job
        release: loki
    spec:
      restartPolicy: OnFailure      
      volumes:
        - name: minio-configuration
          projected:
            sources:
            - configMap:
                name: loki-minio
            - secret:
                name: loki-minio

      serviceAccountName: minio-sa
      containers:
      - name: minio-mc
        image: "quay.io/minio/mc:RELEASE.2022-09-16T09-16-47Z"
        imagePullPolicy: IfNotPresent
        command: ["/bin/sh", "/config/initialize"]
        env:
          - name: MINIO_ENDPOINT
            value: loki-minio
          - name: MINIO_PORT
            value: "9000"
        volumeMounts:
          - name: minio-configuration
            mountPath: /config
        resources:
          requests:
            memory: 128Mi
---
# Source: loki/charts/minio/templates/post-install-create-user-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: loki-minio-make-user-job
  namespace: "default"
  labels:
    app: minio-make-user-job
    chart: minio-4.0.15
    release: loki
    heritage: Helm
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  template:
    metadata:
      labels:
        app: minio-job
        release: loki
    spec:
      restartPolicy: OnFailure      
      volumes:
        - name: minio-configuration
          projected:
            sources:
            - configMap:
                name: loki-minio
            - secret:
                name: loki-minio

      serviceAccountName: minio-sa
      containers:
      - name: minio-mc
        image: "quay.io/minio/mc:RELEASE.2022-09-16T09-16-47Z"
        imagePullPolicy: IfNotPresent
        command: ["/bin/sh", "/config/add-user"]
        env:
          - name: MINIO_ENDPOINT
            value: loki-minio
          - name: MINIO_PORT
            value: "9000"
        volumeMounts:
          - name: minio-configuration
            mountPath: /config
        resources:
          requests:
            memory: 128Mi
MANIFEST:
---
# Source: loki/templates/backend/poddisruptionbudget-backend.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: loki-backend
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: backend
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
      app.kubernetes.io/instance: loki
      app.kubernetes.io/component: backend
  maxUnavailable: 1
---
# Source: loki/templates/chunks-cache/poddisruptionbudget-chunks-cache.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: loki-memcached-chunks-cache
  namespace: default
  labels:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: memcached-chunks-cache
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
      app.kubernetes.io/instance: loki
      app.kubernetes.io/component: memcached-chunks-cache
  maxUnavailable: 1
---
# Source: loki/templates/read/poddisruptionbudget-read.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: loki-read
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: read
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
      app.kubernetes.io/instance: loki
      app.kubernetes.io/component: read
  maxUnavailable: 1
---
# Source: loki/templates/results-cache/poddisruptionbudget-results-cache.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: loki-memcached-results-cache
  namespace: default
  labels:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: memcached-results-cache
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
      app.kubernetes.io/instance: loki
      app.kubernetes.io/component: memcached-results-cache
  maxUnavailable: 1
---
# Source: loki/templates/write/poddisruptionbudget-write.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: loki-write
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: write
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
      app.kubernetes.io/instance: loki
      app.kubernetes.io/component: write
  maxUnavailable: 1
---
# Source: loki/charts/minio/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "minio-sa"
  namespace: "default"
---
# Source: loki/templates/loki-canary/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: loki-canary
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: canary
automountServiceAccountToken: true
---
# Source: loki/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: loki
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: loki/charts/minio/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: loki-minio
  namespace: "default"
  labels:
    app: minio
    chart: minio-4.0.15
    release: loki
    heritage: Helm
type: Opaque
data:
  rootUser: "ZW50ZXJwcmlzZS1sb2dz"
  rootPassword: "c3VwZXJzZWNyZXQ="
---
# Source: loki/charts/minio/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-minio
  namespace: "default"
  labels:
    app: minio
    chart: minio-4.0.15
    release: loki
    heritage: Helm
data:
  initialize: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
    
    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }
    
    # checkBucketExists ($bucket)
    # Check if the bucket exists, by using the exit code of `mc ls`
    checkBucketExists() {
      BUCKET=$1
      CMD=$(${MC} ls myminio/$BUCKET > /dev/null 2>&1)
      return $?
    }
    
    # createBucket ($bucket, $policy, $purge)
    # Ensure bucket exists, purging if asked to
    createBucket() {
      BUCKET=$1
      POLICY=$2
      PURGE=$3
      VERSIONING=$4
      OBJECTLOCKING=$5
    
      # Purge the bucket, if set & exists
      # Since PURGE is user input, check explicitly for `true`
      if [ $PURGE = true ]; then
        if checkBucketExists $BUCKET ; then
          echo "Purging bucket '$BUCKET'."
          set +e ; # don't exit if this fails
          ${MC} rm -r --force myminio/$BUCKET
          set -e ; # reset `e` as active
        else
          echo "Bucket '$BUCKET' does not exist, skipping purge."
        fi
      fi
    
    # Create the bucket if it does not exist and set objectlocking if enabled (NOTE: versioning will be not changed if OBJECTLOCKING is set because it enables versioning to the Buckets created)
    if ! checkBucketExists $BUCKET ; then
        if [ ! -z $OBJECTLOCKING ] ; then
          if [ $OBJECTLOCKING = true ] ; then
              echo "Creating bucket with OBJECTLOCKING '$BUCKET'"
              ${MC} mb --with-lock myminio/$BUCKET
          elif [ $OBJECTLOCKING = false ] ; then
                echo "Creating bucket '$BUCKET'"
                ${MC} mb myminio/$BUCKET
          fi
      elif [ -z $OBJECTLOCKING ] ; then
            echo "Creating bucket '$BUCKET'"
            ${MC} mb myminio/$BUCKET
      else
        echo "Bucket '$BUCKET' already exists."  
      fi
      fi
    
    
      # set versioning for bucket if objectlocking is disabled or not set
      if [ -z $OBJECTLOCKING ] ; then
      if [ ! -z $VERSIONING ] ; then
        if [ $VERSIONING = true ] ; then
            echo "Enabling versioning for '$BUCKET'"
            ${MC} version enable myminio/$BUCKET
        elif [ $VERSIONING = false ] ; then
            echo "Suspending versioning for '$BUCKET'"
            ${MC} version suspend myminio/$BUCKET
        fi
        fi
      else
          echo "Bucket '$BUCKET' versioning unchanged."
      fi
    
    
      # At this point, the bucket should exist, skip checking for existence
      # Set policy on the bucket
      echo "Setting policy of bucket '$BUCKET' to '$POLICY'."
      ${MC} policy set $POLICY myminio/$BUCKET
    }
    
    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme
    
    
    
    # Create the buckets
    createBucket chunks none false  
    createBucket ruler none false  
    createBucket admin none false  
  add-user: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
    
    # AccessKey and secretkey credentials file are added to prevent shell execution errors caused by special characters.
    # Special characters for example : ',",<,>,{,}
    MINIO_ACCESSKEY_SECRETKEY_TMP="/tmp/accessKey_and_secretKey_tmp"
    
    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }
    
    # checkUserExists ()
    # Check if the user exists, by using the exit code of `mc admin user info`
    checkUserExists() {
      CMD=$(${MC} admin user info myminio $(head -1 $MINIO_ACCESSKEY_SECRETKEY_TMP) > /dev/null 2>&1)
      return $?
    }
    
    # createUser ($policy)
    createUser() {
      POLICY=$1
      #check accessKey_and_secretKey_tmp file
      if [[ ! -f $MINIO_ACCESSKEY_SECRETKEY_TMP ]];then
        echo "credentials file does not exist"
        return 1
      fi
      if [[ $(cat $MINIO_ACCESSKEY_SECRETKEY_TMP|wc -l) -ne 2 ]];then
        echo "credentials file is invalid"
        rm -f $MINIO_ACCESSKEY_SECRETKEY_TMP
        return 1
      fi
      USER=$(head -1 $MINIO_ACCESSKEY_SECRETKEY_TMP)
      # Create the user if it does not exist
      if ! checkUserExists ; then
        echo "Creating user '$USER'"
        cat $MINIO_ACCESSKEY_SECRETKEY_TMP | ${MC} admin user add myminio
      else
        echo "User '$USER' already exists."
      fi
      #clean up credentials files.
      rm -f $MINIO_ACCESSKEY_SECRETKEY_TMP
    
      # set policy for user
      if [ ! -z $POLICY -a $POLICY != " " ] ; then
          echo "Adding policy '$POLICY' for '$USER'"
          ${MC} admin policy set myminio $POLICY user=$USER
      else
          echo "User '$USER' has no policy attached."
      fi
    }
    
    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme
    
    
    
    # Create the users
    echo console > $MINIO_ACCESSKEY_SECRETKEY_TMP
    echo console123 >> $MINIO_ACCESSKEY_SECRETKEY_TMP
    createUser consoleAdmin
    
  add-policy: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
    
    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }
    
    # checkPolicyExists ($policy)
    # Check if the policy exists, by using the exit code of `mc admin policy info`
    checkPolicyExists() {
      POLICY=$1
      CMD=$(${MC} admin policy info myminio $POLICY > /dev/null 2>&1)
      return $?
    }
    
    # createPolicy($name, $filename)
    createPolicy () {
      NAME=$1
      FILENAME=$2
    
      # Create the name if it does not exist
      echo "Checking policy: $NAME (in /config/$FILENAME.json)"
      if ! checkPolicyExists $NAME ; then
        echo "Creating policy '$NAME'"
      else
        echo "Policy '$NAME' already exists."
      fi
      ${MC} admin policy add myminio $NAME /config/$FILENAME.json
    
    }
    
    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme
    
    
  custom-command: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
    
    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }
    
    # runCommand ($@)
    # Run custom mc command
    runCommand() {
      ${MC} "$@"
      return $?
    }
    
    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme
---
# Source: loki/templates/config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
data:
  config.yaml: |
    
    auth_enabled: true
    bloom_build:
      builder:
        planner_address: loki-backend-headless.default.svc.cluster.local:9095
      enabled: false
    bloom_gateway:
      client:
        addresses: dnssrvnoa+_grpc._tcp.loki-backend-headless.default.svc.cluster.local
      enabled: false
    chunk_store_config:
      chunk_cache_config:
        background:
          writeback_buffer: 500000
          writeback_goroutines: 1
          writeback_size_limit: 500MB
        default_validity: 0s
        memcached:
          batch_size: 4
          parallelism: 5
        memcached_client:
          addresses: dnssrvnoa+_memcached-client._tcp.loki-chunks-cache.default.svc
          consistent_hash: true
          max_idle_conns: 72
          timeout: 2000ms
    common:
      compactor_address: 'http://loki-backend:3100'
      path_prefix: /var/loki
      replication_factor: 3
      storage:
        s3:
          access_key_id: enterprise-logs
          bucketnames: chunks
          endpoint: loki-minio.default.svc:9000
          insecure: true
          s3forcepathstyle: true
          secret_access_key: supersecret
    frontend:
      scheduler_address: ""
      tail_proxy_url: ""
    frontend_worker:
      scheduler_address: ""
    index_gateway:
      mode: simple
    ingester:
      chunk_encoding: snappy
    limits_config:
      max_cache_freshness_per_query: 10m
      query_timeout: 300s
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      split_queries_by_interval: 15m
      volume_enabled: true
    memberlist:
      join_members:
      - loki-memberlist
    pattern_ingester:
      enabled: false
    querier:
      max_concurrent: 4
    query_range:
      align_queries_with_step: true
      cache_results: true
      results_cache:
        cache:
          background:
            writeback_buffer: 500000
            writeback_goroutines: 1
            writeback_size_limit: 500MB
          default_validity: 12h
          memcached_client:
            addresses: dnssrvnoa+_memcached-client._tcp.loki-results-cache.default.svc
            consistent_hash: true
            timeout: 500ms
            update_interval: 1m
    ruler:
      storage:
        s3:
          bucketnames: ruler
        type: s3
    runtime_config:
      file: /etc/loki/runtime-config/runtime-config.yaml
    schema_config:
      configs:
      - from: "2024-04-01"
        index:
          period: 24h
          prefix: loki_index_
        object_store: s3
        schema: v13
        store: tsdb
    server:
      grpc_listen_port: 9095
      http_listen_port: 3100
      http_server_read_timeout: 600s
      http_server_write_timeout: 600s
    storage_config:
      bloom_shipper:
        working_directory: /var/loki/data/bloomshipper
      boltdb_shipper:
        index_gateway_client:
          server_address: dns+loki-backend-headless.default.svc.cluster.local:9095
      hedging:
        at: 250ms
        max_per_second: 20
        up_to: 3
      tsdb_shipper:
        index_gateway_client:
          server_address: dns+loki-backend-headless.default.svc.cluster.local:9095
    tracing:
      enabled: true
---
# Source: loki/templates/gateway/configmap-gateway.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-gateway
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: gateway
data:
  nginx.conf: |    
    worker_processes  5;  ## Default: 1
    error_log  /dev/stderr;
    pid        /tmp/nginx.pid;
    worker_rlimit_nofile 8192;
    
    events {
      worker_connections  4096;  ## Default: 1024
    }
    
    http {
      client_body_temp_path /tmp/client_temp;
      proxy_temp_path       /tmp/proxy_temp_path;
      fastcgi_temp_path     /tmp/fastcgi_temp;
      uwsgi_temp_path       /tmp/uwsgi_temp;
      scgi_temp_path        /tmp/scgi_temp;
    
      client_max_body_size  4M;
    
      proxy_read_timeout    600; ## 10 minutes
      proxy_send_timeout    600;
      proxy_connect_timeout 600;
    
      proxy_http_version    1.1;
    
      default_type application/octet-stream;
      log_format   main '$remote_addr - $remote_user [$time_local]  $status '
            '"$request" $body_bytes_sent "$http_referer" '
            '"$http_user_agent" "$http_x_forwarded_for"';
      access_log   /dev/stderr  main;
    
      sendfile     on;
      tcp_nopush   on;
      resolver kube-dns.kube-system.svc.cluster.local.;
      
    
      server {
        listen             8080;
        listen             [::]:8080;
    
        location = / {
          return 200 'OK';
          auth_basic off;
        }
    
        ########################################################
        # Configure backend targets# Distributor
        location = /api/prom/push {
          proxy_pass       http://loki-write.default.svc.cluster.local:3100$request_uri;
        }
        location = /loki/api/v1/push {
          proxy_pass       http://loki-write.default.svc.cluster.local:3100$request_uri;
        }
        location = /distributor/ring {
          proxy_pass       http://loki-write.default.svc.cluster.local:3100$request_uri;
        }
        location = /otlp/v1/logs {
          proxy_pass       http://loki-write.default.svc.cluster.local:3100$request_uri;
        }
    
        # Ingester
        location = /flush {
          proxy_pass       http://loki-write.default.svc.cluster.local:3100$request_uri;
        }
        location ^~ /ingester/ {
          proxy_pass       http://loki-write.default.svc.cluster.local:3100$request_uri;
        }
        location = /ingester {
          internal;        # to suppress 301
        }
    
        # Ring
        location = /ring {
          proxy_pass       http://loki-write.default.svc.cluster.local:3100$request_uri;
        }
    
        # MemberListKV
        location = /memberlist {
          proxy_pass       http://loki-write.default.svc.cluster.local:3100$request_uri;
        }
    
        # Ruler
        location = /ruler/ring {
          proxy_pass       http://loki-backend.default.svc.cluster.local:3100$request_uri;
        }
        location = /api/prom/rules {
          proxy_pass       http://loki-backend.default.svc.cluster.local:3100$request_uri;
        }
        location ^~ /api/prom/rules/ {
          proxy_pass       http://loki-backend.default.svc.cluster.local:3100$request_uri;
        }
        location = /loki/api/v1/rules {
          proxy_pass       http://loki-backend.default.svc.cluster.local:3100$request_uri;
        }
        location ^~ /loki/api/v1/rules/ {
          proxy_pass       http://loki-backend.default.svc.cluster.local:3100$request_uri;
        }
        location = /prometheus/api/v1/alerts {
          proxy_pass       http://loki-backend.default.svc.cluster.local:3100$request_uri;
        }
        location = /prometheus/api/v1/rules {
          proxy_pass       http://loki-backend.default.svc.cluster.local:3100$request_uri;
        }
    
        # Compactor
        location = /compactor/ring {
          proxy_pass       http://loki-backend.default.svc.cluster.local:3100$request_uri;
        }
        location = /loki/api/v1/delete {
          proxy_pass       http://loki-backend.default.svc.cluster.local:3100$request_uri;
        }
        location = /loki/api/v1/cache/generation_numbers {
          proxy_pass       http://loki-backend.default.svc.cluster.local:3100$request_uri;
        }
    
        # IndexGateway
        location = /indexgateway/ring {
          proxy_pass       http://loki-backend.default.svc.cluster.local:3100$request_uri;
        }
    
        # QueryScheduler
        location = /scheduler/ring {
          proxy_pass       http://loki-backend.default.svc.cluster.local:3100$request_uri;
        }
    
        # Config
        location = /config {
          proxy_pass       http://loki-write.default.svc.cluster.local:3100$request_uri;
        }
    
    
        # QueryFrontend, Querier
        location = /api/prom/tail {
          proxy_pass       http://loki-read.default.svc.cluster.local:3100$request_uri;
          proxy_set_header Upgrade $http_upgrade;
          proxy_set_header Connection "upgrade";
        }
        location = /loki/api/v1/tail {
          proxy_pass       http://loki-read.default.svc.cluster.local:3100$request_uri;
          proxy_set_header Upgrade $http_upgrade;
          proxy_set_header Connection "upgrade";
        }
        location ^~ /api/prom/ {
          proxy_pass       http://loki-read.default.svc.cluster.local:3100$request_uri;
        }
        location = /api/prom {
          internal;        # to suppress 301
        }
        location ^~ /loki/api/v1/ {
          proxy_pass       http://loki-read.default.svc.cluster.local:3100$request_uri;
        }
        location = /loki/api/v1 {
          internal;        # to suppress 301
        }
      }
    }
---
# Source: loki/templates/runtime-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-runtime
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
data:
  runtime-config.yaml: |
    {}
---
# Source: loki/templates/backend/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
  name: loki-clusterrole
rules:
- apiGroups: [""] # "" indicates the core API group
  resources: ["configmaps", "secrets"]
  verbs: ["get", "watch", "list"]
---
# Source: loki/templates/backend/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: loki-clusterrolebinding
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: loki
    namespace: default
roleRef:
  kind: ClusterRole
  name: loki-clusterrole
  apiGroup: rbac.authorization.k8s.io
---
# Source: loki/charts/minio/templates/console-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-minio-console
  namespace: "default"
  labels:
    app: minio
    chart: minio-4.0.15
    release: loki
    heritage: Helm
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9001
      protocol: TCP
      targetPort: 9001
  selector:
    app: minio
    release: loki
---
# Source: loki/charts/minio/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-minio
  namespace: "default"
  labels:
    app: minio
    chart: minio-4.0.15
    release: loki
    heritage: Helm
    monitoring: "true"
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9000
      protocol: TCP
      targetPort: 9000
  selector:
    app: minio
    release: loki
---
# Source: loki/charts/minio/templates/statefulset.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-minio-svc
  namespace: "default"
  labels:
    app: minio
    chart: minio-4.0.15
    release: "loki"
    heritage: "Helm"
spec:
  publishNotReadyAddresses: true
  clusterIP: None
  ports:
    - name: http
      port: 9000
      protocol: TCP
      targetPort: 9000
  selector:
    app: minio
    release: loki
---
# Source: loki/templates/backend/query-scheduler-discovery.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-query-scheduler-discovery
  namespace: default
  labels:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: backend
    prometheus.io/service-monitor: "false"
  annotations:
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: http-metrics
      port: 3100
      targetPort: http-metrics
      protocol: TCP
    - name: grpc
      port: 9095
      targetPort: grpc
      protocol: TCP
  selector:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: backend
---
# Source: loki/templates/backend/service-backend-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-backend-headless
  namespace: default
  labels:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: backend
    variant: headless
    prometheus.io/service-monitor: "false"
  annotations:
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: http-metrics
      port: 3100
      targetPort: http-metrics
      protocol: TCP
    - name: grpc
      port: 9095
      targetPort: grpc
      protocol: TCP
  selector:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: backend
---
# Source: loki/templates/backend/service-backend.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-backend
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: backend
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: http-metrics
      port: 3100
      targetPort: http-metrics
      protocol: TCP
    - name: grpc
      port: 9095
      targetPort: grpc
      protocol: TCP
  selector:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: backend
---
# Source: loki/templates/chunks-cache/service-chunks-cache-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-chunks-cache
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "memcached-chunks-cache"
  annotations:
    {}
  namespace: "default"
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: memcached-client
      port: 11211
      targetPort: 11211
    - name: http-metrics
      port: 9150
      targetPort: 9150
    
  selector:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: "memcached-chunks-cache"
---
# Source: loki/templates/gateway/service-gateway.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-gateway
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: gateway
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: http-metrics
      port: 80
      targetPort: http-metrics
      protocol: TCP
  selector:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: gateway
---
# Source: loki/templates/loki-canary/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-canary
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: canary
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: http-metrics
      port: 3500
      targetPort: http-metrics
      protocol: TCP
  selector:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: canary
---
# Source: loki/templates/read/service-read-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-read-headless
  namespace: default
  labels:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: read
    variant: headless
    prometheus.io/service-monitor: "false"
  annotations:
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: http-metrics
      port: 3100
      targetPort: http-metrics
      protocol: TCP
    - name: grpc
      port: 9095
      targetPort: grpc
      protocol: TCP
      appProtocol: tcp
  selector:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: read
---
# Source: loki/templates/read/service-read.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-read
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: read
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: http-metrics
      port: 3100
      targetPort: http-metrics
      protocol: TCP
    - name: grpc
      port: 9095
      targetPort: grpc
      protocol: TCP
  selector:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: read
---
# Source: loki/templates/results-cache/service-results-cache-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-results-cache
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "memcached-results-cache"
  annotations:
    {}
  namespace: "default"
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: memcached-client
      port: 11211
      targetPort: 11211
    - name: http-metrics
      port: 9150
      targetPort: 9150
    
  selector:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: "memcached-results-cache"
---
# Source: loki/templates/service-memberlist.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-memberlist
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp
      port: 7946
      targetPort: http-memberlist
      protocol: TCP
  selector:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/part-of: memberlist
---
# Source: loki/templates/write/service-write-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-write-headless
  namespace: default
  labels:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: write
    variant: headless
    prometheus.io/service-monitor: "false"
  annotations:
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: http-metrics
      port: 3100
      targetPort: http-metrics
      protocol: TCP
    - name: grpc
      port: 9095
      targetPort: grpc
      protocol: TCP
      appProtocol: tcp
  selector:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: write
---
# Source: loki/templates/write/service-write.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-write
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: write
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: http-metrics
      port: 3100
      targetPort: http-metrics
      protocol: TCP
    - name: grpc
      port: 9095
      targetPort: grpc
      protocol: TCP
  selector:
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/component: write
---
# Source: loki/templates/loki-canary/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: loki-canary
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: canary
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
      app.kubernetes.io/instance: loki
      app.kubernetes.io/component: canary
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: loki
        app.kubernetes.io/instance: loki
        app.kubernetes.io/component: canary
    spec:
      serviceAccountName: loki-canary
      
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      containers:
        - name: loki-canary
          image: docker.io/grafana/loki-canary:3.1.1
          imagePullPolicy: IfNotPresent
          args:
            - -addr=loki-gateway.default.svc.cluster.local.:80
            - -labelname=pod
            - -labelvalue=$(POD_NAME)
            - -user=self-monitoring
            - -tenant-id=self-monitoring
            - -pass=
            - -push=true
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          volumeMounts:
          ports:
            - name: http-metrics
              containerPort: 3500
              protocol: TCP
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            
          readinessProbe:
            httpGet:
              path: /metrics
              port: http-metrics
            initialDelaySeconds: 15
            timeoutSeconds: 1
      volumes:
---
# Source: loki/templates/gateway/deployment-gateway-nginx.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki-gateway
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: gateway
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
      app.kubernetes.io/instance: loki
      app.kubernetes.io/component: gateway
  template:
    metadata:
      annotations:
        checksum/config: 96c2a0551bc07e1b83e40e9c3bd24e686c44486fee59a58d2c8d96bd5b72452e
      labels:
        app.kubernetes.io/name: loki
        app.kubernetes.io/instance: loki
        app.kubernetes.io/component: gateway
    spec:
      serviceAccountName: loki
      enableServiceLinks: true
      
      securityContext:
        fsGroup: 101
        runAsGroup: 101
        runAsNonRoot: true
        runAsUser: 101
      terminationGracePeriodSeconds: 30
      containers:
        - name: nginx
          image: docker.io/nginxinc/nginx-unprivileged:1.27-alpine
          imagePullPolicy: IfNotPresent
          ports:
            - name: http-metrics
              containerPort: 8080
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /
              port: http-metrics
            initialDelaySeconds: 15
            timeoutSeconds: 1
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          volumeMounts:
            - name: config
              mountPath: /etc/nginx
            - name: tmp
              mountPath: /tmp
            - name: docker-entrypoint-d-override
              mountPath: /docker-entrypoint.d
          resources:
            {}
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: gateway
            topologyKey: kubernetes.io/hostname
      volumes:
        - name: config
          configMap:
            name: loki-gateway
        - name: tmp
          emptyDir: {}
        - name: docker-entrypoint-d-override
          emptyDir: {}
---
# Source: loki/templates/read/deployment-read.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki-read
  namespace: default
  labels:
    app.kubernetes.io/part-of: memberlist
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: read
spec:
  replicas: 3
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
      app.kubernetes.io/instance: loki
      app.kubernetes.io/component: read
  template:
    metadata:
      annotations:
        checksum/config: 520868e0daab0cfae664512feb3ae461d42f468b37515e44eca93c8b7da2d2f9
      labels:
        app.kubernetes.io/part-of: memberlist
        app.kubernetes.io/name: loki
        app.kubernetes.io/instance: loki
        app.kubernetes.io/component: read
    spec:
      serviceAccountName: loki
      automountServiceAccountToken: true
      
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      terminationGracePeriodSeconds: 30
      containers:
        - name: loki
          image: docker.io/grafana/loki:3.1.1
          imagePullPolicy: IfNotPresent
          args:
            - -config.file=/etc/loki/config/config.yaml
            - -target=read
            - -legacy-read-mode=false
            - -common.compactor-grpc-address=loki-backend.default.svc.cluster.local:9095
          ports:
            - name: http-metrics
              containerPort: 3100
              protocol: TCP
            - name: grpc
              containerPort: 9095
              protocol: TCP
            - name: http-memberlist
              containerPort: 7946
              protocol: TCP
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          readinessProbe:
            httpGet:
              path: /ready
              port: http-metrics
            initialDelaySeconds: 30
            timeoutSeconds: 1
          volumeMounts:
            - name: config
              mountPath: /etc/loki/config
            - name: runtime-config
              mountPath: /etc/loki/runtime-config
            - name: tmp
              mountPath: /tmp
            - name: data
              mountPath: /var/loki
          resources:
            {}
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: read
            topologyKey: kubernetes.io/hostname
      volumes:
        - name: tmp
          emptyDir: {}
        - name: data
          emptyDir: {}
        - name: config
          configMap:
            name: loki
            items:
              - key: "config.yaml"
                path: "config.yaml"
        - name: runtime-config
          configMap:
            name: loki-runtime
---
# Source: loki/charts/minio/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki-minio
  namespace: "default"
  labels:
    app: minio
    chart: minio-4.0.15
    release: loki
    heritage: Helm
spec:
  updateStrategy:
    type: RollingUpdate
  podManagementPolicy: "Parallel"
  serviceName: loki-minio-svc
  replicas: 1
  selector:
    matchLabels:
      app: minio
      release: loki
  template:
    metadata:
      name: loki-minio
      labels:
        app: minio
        release: loki
      annotations:
        checksum/secrets: 06573763dc90ff6665c7dca1ba8ec15d7ff909a988372a719880d0918da249ab
        checksum/config: 5ccf6de054849c650529eddba7e4c1d6dde7e79291d93059e1d1ca68067e5d5c
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        fsGroupChangePolicy: OnRootMismatch

      serviceAccountName: minio-sa
      containers:
        - name: minio
          image: quay.io/minio/minio:RELEASE.2022-09-17T00-09-45Z
          imagePullPolicy: IfNotPresent

          command: [ "/bin/sh",
            "-ce",
            "/usr/bin/docker-entrypoint.sh minio server  http://loki-minio-{0...0}.loki-minio-svc.default.svc.cluster.local/export-{0...1} -S /etc/minio/certs/ --address :9000 --console-address :9001" ]
          volumeMounts:
            - name: export-0
              mountPath: /export-0
            - name: export-1
              mountPath: /export-1            
          ports:
            - name: http
              containerPort: 9000
            - name: http-console
              containerPort: 9001
          env:
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: loki-minio
                  key: rootUser
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: loki-minio
                  key: rootPassword
            - name: MINIO_PROMETHEUS_AUTH_TYPE
              value: "public"
          resources:
            requests:
              cpu: 100m
              memory: 128Mi      
      volumes:
        - name: minio-user
          secret:
            secretName: loki-minio        
  volumeClaimTemplates:
    - metadata:
        name: export-0
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 5Gi
    - metadata:
        name: export-1
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 5Gi
---
# Source: loki/templates/backend/statefulset-backend.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki-backend
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: backend
    app.kubernetes.io/part-of: memberlist
spec:
  replicas: 3
  podManagementPolicy: Parallel
  updateStrategy:
    rollingUpdate:
      partition: 0
  serviceName: loki-backend-headless
  revisionHistoryLimit: 10
  
  persistentVolumeClaimRetentionPolicy:
    whenDeleted: Delete
    whenScaled: Delete
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
      app.kubernetes.io/instance: loki
      app.kubernetes.io/component: backend
  template:
    metadata:
      annotations:
        checksum/config: 520868e0daab0cfae664512feb3ae461d42f468b37515e44eca93c8b7da2d2f9
      labels:
        app.kubernetes.io/name: loki
        app.kubernetes.io/instance: loki
        app.kubernetes.io/component: backend
        app.kubernetes.io/part-of: memberlist
    spec:
      serviceAccountName: loki
      automountServiceAccountToken: true
      
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      terminationGracePeriodSeconds: 300
      containers:
        - name: loki-sc-rules
          image: "kiwigrid/k8s-sidecar:1.27.5"
          imagePullPolicy: IfNotPresent
          env:
            - name: METHOD
              value: WATCH
            - name: LABEL
              value: "loki_rule"
            - name: FOLDER
              value: "/rules"
            - name: RESOURCE
              value: "both"
            - name: WATCH_SERVER_TIMEOUT
              value: "60"
            - name: WATCH_CLIENT_TIMEOUT
              value: "60"
            - name: LOG_LEVEL
              value: "INFO"
          volumeMounts:
            - name: sc-rules-volume
              mountPath: "/rules"
        - name: loki
          image: docker.io/grafana/loki:3.1.1
          imagePullPolicy: IfNotPresent
          args:
            - -config.file=/etc/loki/config/config.yaml
            - -target=backend
            - -legacy-read-mode=false
          ports:
            - name: http-metrics
              containerPort: 3100
              protocol: TCP
            - name: grpc
              containerPort: 9095
              protocol: TCP
            - name: http-memberlist
              containerPort: 7946
              protocol: TCP
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          readinessProbe:
            httpGet:
              path: /ready
              port: http-metrics
            initialDelaySeconds: 30
            timeoutSeconds: 1
          volumeMounts:
            - name: config
              mountPath: /etc/loki/config
            - name: runtime-config
              mountPath: /etc/loki/runtime-config
            - name: tmp
              mountPath: /tmp
            - name: data
              mountPath: /var/loki
            - name: sc-rules-volume
              mountPath: "/rules"
          resources:
            {}
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: backend
            topologyKey: kubernetes.io/hostname
      volumes:
        - name: tmp
          emptyDir: {}
        - name: config
          configMap:
            name: loki
            items:
              - key: "config.yaml"
                path: "config.yaml"
        - name: runtime-config
          configMap:
            name: loki-runtime
        - name: sc-rules-volume
          emptyDir: {}
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: "10Gi"
---
# Source: loki/templates/chunks-cache/statefulset-chunks-cache.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki-chunks-cache
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "memcached-chunks-cache"
    name: "memcached-chunks-cache"
  annotations:
    {}
  namespace: "default"
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
      app.kubernetes.io/instance: loki
      app.kubernetes.io/component: "memcached-chunks-cache"
      name: "memcached-chunks-cache"
  updateStrategy:
    type: RollingUpdate
  serviceName: loki-chunks-cache

  template:
    metadata:
      labels:
        app.kubernetes.io/name: loki
        app.kubernetes.io/instance: loki
        app.kubernetes.io/component: "memcached-chunks-cache"
        name: "memcached-chunks-cache"
      annotations:

    spec:
      serviceAccountName: loki
      securityContext:
        fsGroup: 11211
        runAsGroup: 11211
        runAsNonRoot: true
        runAsUser: 11211
      initContainers:
        []
      nodeSelector:
        {}
      affinity:
        {}
      topologySpreadConstraints:
        []
      tolerations:
        []
      terminationGracePeriodSeconds: 60
      containers:
        - name: memcached
          image: memcached:1.6.23-alpine
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 9830Mi
            requests:
              cpu: 500m
              memory: 9830Mi
          ports:
            - containerPort: 11211
              name: client
          args:
            - -m 8192
            - --extended=modern,track_sizes
            - -I 5m
            - -c 16384
            - -v
            - -u 11211
          env:
          envFrom:
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
        - name: exporter
          image: prom/memcached-exporter:v0.14.2
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9150
              name: http-metrics
          args:
            - "--memcached.address=localhost:11211"
            - "--web.listen-address=0.0.0.0:9150"
          resources:
            limits: {}
            requests: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
---
# Source: loki/templates/results-cache/statefulset-results-cache.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki-results-cache
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "memcached-results-cache"
    name: "memcached-results-cache"
  annotations:
    {}
  namespace: "default"
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
      app.kubernetes.io/instance: loki
      app.kubernetes.io/component: "memcached-results-cache"
      name: "memcached-results-cache"
  updateStrategy:
    type: RollingUpdate
  serviceName: loki-results-cache

  template:
    metadata:
      labels:
        app.kubernetes.io/name: loki
        app.kubernetes.io/instance: loki
        app.kubernetes.io/component: "memcached-results-cache"
        name: "memcached-results-cache"
      annotations:

    spec:
      serviceAccountName: loki
      securityContext:
        fsGroup: 11211
        runAsGroup: 11211
        runAsNonRoot: true
        runAsUser: 11211
      initContainers:
        []
      nodeSelector:
        {}
      affinity:
        {}
      topologySpreadConstraints:
        []
      tolerations:
        []
      terminationGracePeriodSeconds: 60
      containers:
        - name: memcached
          image: memcached:1.6.23-alpine
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1229Mi
            requests:
              cpu: 500m
              memory: 1229Mi
          ports:
            - containerPort: 11211
              name: client
          args:
            - -m 1024
            - --extended=modern,track_sizes
            - -I 5m
            - -c 16384
            - -v
            - -u 11211
          env:
          envFrom:
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
        - name: exporter
          image: prom/memcached-exporter:v0.14.2
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9150
              name: http-metrics
          args:
            - "--memcached.address=localhost:11211"
            - "--web.listen-address=0.0.0.0:9150"
          resources:
            limits: {}
            requests: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
---
# Source: loki/templates/write/statefulset-write.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki-write
  namespace: default
  labels:
    helm.sh/chart: loki-6.16.0
    app.kubernetes.io/name: loki
    app.kubernetes.io/instance: loki
    app.kubernetes.io/version: "3.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: write
    app.kubernetes.io/part-of: memberlist
spec:
  replicas: 3
  podManagementPolicy: Parallel
  updateStrategy:
    rollingUpdate:
      partition: 0
  serviceName: loki-write-headless
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
      app.kubernetes.io/instance: loki
      app.kubernetes.io/component: write
  template:
    metadata:
      annotations:
        checksum/config: 520868e0daab0cfae664512feb3ae461d42f468b37515e44eca93c8b7da2d2f9
      labels:
        app.kubernetes.io/name: loki
        app.kubernetes.io/instance: loki
        app.kubernetes.io/component: write
        app.kubernetes.io/part-of: memberlist
    spec:
      serviceAccountName: loki
      automountServiceAccountToken: true
      enableServiceLinks: true
      
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      terminationGracePeriodSeconds: 300
      containers:
        - name: loki
          image: docker.io/grafana/loki:3.1.1
          imagePullPolicy: IfNotPresent
          args:
            - -config.file=/etc/loki/config/config.yaml
            - -target=write
          ports:
            - name: http-metrics
              containerPort: 3100
              protocol: TCP
            - name: grpc
              containerPort: 9095
              protocol: TCP
            - name: http-memberlist
              containerPort: 7946
              protocol: TCP
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          readinessProbe:
            httpGet:
              path: /ready
              port: http-metrics
            initialDelaySeconds: 30
            timeoutSeconds: 1
          volumeMounts:
            - name: config
              mountPath: /etc/loki/config
            - name: runtime-config
              mountPath: /etc/loki/runtime-config
            - name: data
              mountPath: /var/loki
          resources:
            {}
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: write
            topologyKey: kubernetes.io/hostname
      volumes:
        - name: config
          configMap:
            name: loki
            items:
              - key: "config.yaml"
                path: "config.yaml"
        - name: runtime-config
          configMap:
            name: loki-runtime
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: "10Gi"

NOTES:
***********************************************************************
 Welcome to Grafana Loki
 Chart version: 6.16.0
 Chart Name: loki
 Loki version: 3.1.1
***********************************************************************

** Please be patient while the chart is being deployed **

Tip:

  Watch the deployment status using the command: kubectl get pods -w --namespace default

If pods are taking too long to schedule make sure pod affinity can be fulfilled in the current cluster.

***********************************************************************
Installed components:
***********************************************************************
* gateway
* minio
* read
* write
* backend


***********************************************************************
Sending logs to Loki
***********************************************************************

Loki has been configured with a gateway (nginx) to support reads and writes from a single component.

You can send logs from inside the cluster using the cluster DNS:

http://loki-gateway.default.svc.cluster.local/loki/api/v1/push

You can test to send data from outside the cluster by port-forwarding the gateway to your local machine:

  kubectl port-forward --namespace default svc/loki-gateway 3100:80 &

And then using http://127.0.0.1:3100/loki/api/v1/push URL as shown below:

```
curl -H "Content-Type: application/json" -XPOST -s "http://127.0.0.1:3100/loki/api/v1/push"  \
--data-raw "{\"streams\": [{\"stream\": {\"job\": \"test\"}, \"values\": [[\"$(date +%s)000000000\", \"fizzbuzz\"]]}]}" \
-H X-Scope-OrgId:foo
```

Then verify that Loki did received the data using the following command:

```
curl "http://127.0.0.1:3100/loki/api/v1/query_range" --data-urlencode 'query={job="test"}' -H X-Scope-OrgId:foo | jq .data.result
```

***********************************************************************
Connecting Grafana to Loki
***********************************************************************

If Grafana operates within the cluster, you'll set up a new Loki datasource by utilizing the following URL:

http://loki-gateway.default.svc.cluster.local/

***********************************************************************
Multi-tenancy
***********************************************************************

Loki is configured with auth enabled (multi-tenancy) and expects tenant headers (`X-Scope-OrgID`) to be set for all API calls.

You must configure Grafana's Loki datasource using the `HTTP Headers` section with the `X-Scope-OrgID` to target a specific tenant.
For each tenant, you can create a different datasource.

The agent of your choice must also be configured to propagate this header.
For example, when using Promtail you can use the `tenant` stage. https://grafana.com/docs/loki/latest/send-data/promtail/stages/tenant/

When not provided with the `X-Scope-OrgID` while auth is enabled, Loki will reject reads and writes with a 404 status code `no org id`.

You can also use a reverse proxy, to automatically add the `X-Scope-OrgID` header as suggested by https://grafana.com/docs/loki/latest/operations/authentication/

For more information, read our documentation about multi-tenancy: https://grafana.com/docs/loki/latest/operations/multi-tenancy/

> When using curl you can pass `X-Scope-OrgId` header using `-H X-Scope-OrgId:foo` option, where foo can be replaced with the tenant of your choice.
